{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Movie Review - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import\n",
    "os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nithin/Desktop/learn/3 2/DataScience/Lab\n",
      "<_io.TextIOWrapper name='/home/nithin/Desktop/learn/3 2/DataScience/Lab/tf.ipynb' mode='r' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "fol=os.getcwd()+'/tf.ipynb'\n",
    "fol1=open(fol)\n",
    "print(fol1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = os.listdir('dataset/txt_sentoken/neg') #neg = !ls dataset/txt_sentoken/neg \n",
    "pos = os.listdir('dataset/txt_sentoken/pos') #!ls dataset/txt_sentoken/pos\n",
    "neg_test = !ls dataset/txt_sentoken/neg_test\n",
    "pos_test = !ls dataset/txt_sentoken/pos_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "798\n",
      "798\n"
     ]
    }
   ],
   "source": [
    "parent_path = \"dataset/txt_sentoken/\"\n",
    "print(len(neg))\n",
    "print(len(pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabu= [{},0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocabu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global vocabu\n",
    "def build_voc():\n",
    "    for fol in [('neg/',neg,0),('pos/',pos,1)]:\n",
    "        vocabu[3+fol[2]] = len(fol[1])\n",
    "        for fil in fol[1]:\n",
    "            if os.path.exists(parent_path+fol[0]+fil):\n",
    "                for line in open(parent_path+fol[0]+fil,'r').read().split(sep='\\n'):\n",
    "                    for word in line.split(sep=' '):\n",
    "                        if word in vocabu[0]:\n",
    "                            vocabu[0][word][fol[2]] += 1\n",
    "                        else:\n",
    "                            vocabu[0][word] = [0,0]\n",
    "                            vocabu[0][word][fol[2]] = 1\n",
    "                        vocabu[fol[2]+1] += 1\n",
    "            else:\n",
    "                print(\"Something fishy\")\n",
    "build_voc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "  #pd.read_csv(dire+'neg/'+neg[0],sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocabu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq(fil):\n",
    "    vect = {}\n",
    "    wc = 0\n",
    "    for line in open(fil,'r').read().split(sep='\\n'):\n",
    "        for word in line.split(sep=' '):\n",
    "            #if word in vocab:\n",
    "            if word in vect:\n",
    "                vect[word] += 1\n",
    "            else:\n",
    "                vect[word] = 1\n",
    "            wc += 1\n",
    "    return (vect,wc)\n",
    "#freq('dataset/txt_sentoken/pos/cv086_18371.txt')                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global vocabu\n",
    "def naive_bayes(f):\n",
    "    vect,wc = freq(f)\n",
    "    posi = 0\n",
    "    nega = 0 #probability\n",
    "    #print(vect.keys())\n",
    "    for word in vect.keys():\n",
    "        if word in vocabu[0]:\n",
    "            l = vocabu[0][word]\n",
    "            if l[0] == 0:\n",
    "                #print(k)\n",
    "                l[0] = 1\n",
    "            if l[1] == 0:\n",
    "                l[1] = 1\n",
    "                #print(k)\n",
    "            n = l[0]/vocabu[1]\n",
    "            p = l[1]/vocabu[2]\n",
    "            nega += math.log10(n)*vect[word]\n",
    "            posi += math.log10(p)*vect[word]\n",
    "            #print(p)\n",
    "        #else:\n",
    "            #print(k+' is not in vocabulary ')\n",
    "    #print(nega,posi)\n",
    "    if nega > posi:\n",
    "        return (0,(vect,wc))\n",
    "    return (1,(vect,wc))\n",
    "#    return (10**nega,10**posi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/txt_sentoken/pos_test/cv041_21113.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-97edf49f1a58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnaive_bayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset/txt_sentoken/pos_test/cv041_21113.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-4c83105c7c9f>\u001b[0m in \u001b[0;36mnaive_bayes\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#global vocabu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnaive_bayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mvect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mposi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnega\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m#probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-57c6fa157794>\u001b[0m in \u001b[0;36mfreq\u001b[0;34m(fil)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mvect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mwc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfil\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;31m#if word in vocab:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/txt_sentoken/pos_test/cv041_21113.txt'"
     ]
    }
   ],
   "source": [
    "naive_bayes('dataset/txt_sentoken/pos_test/cv041_21113.txt')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323 404 79.95049504950495 % accurate\n"
     ]
    }
   ],
   "source": [
    "crt = 0\n",
    "incrt = list()\n",
    "eq = 0\n",
    "total = 0\n",
    "for f in neg_test:\n",
    "    x = naive_bayes('dataset/txt_sentoken/neg_test/'+f)\n",
    "    if x[0] == 0:#x == 'negative':#x[0] > x[1]:\n",
    "        crt += 1\n",
    "    #elif x[0] == x[0]:\n",
    "    #    eq += 1\n",
    "    else:\n",
    "        incrt.append(x[1])\n",
    "    total += 1\n",
    "for f in pos_test:\n",
    "    x = naive_bayes('dataset/txt_sentoken/pos_test/'+f)\n",
    "    if x[0] == 1:#x == 'positive':#x[0] < x[1]:\n",
    "        crt += 1\n",
    "    #elif x[0] == x[1]:\n",
    "    #    eq += 1\n",
    "    else:\n",
    "        incrt.append((x[1]))\n",
    "    total += 1\n",
    "print(crt,total,crt/total*100, \"% accurate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global vocabu\n",
    "def naive_bayes(f):\n",
    "    vect,wc = freq(f)\n",
    "    posi = 1\n",
    "    nega = 1 #probability\n",
    "    #print(vect.keys())\n",
    "    for word in vect.keys():\n",
    "        if word in vocabu[0]:\n",
    "            l = vocabu[0][word]\n",
    "            if l[0] == 0:\n",
    "                #print(k)\n",
    "                l[0] = 1\n",
    "            if l[1] == 0:\n",
    "                l[1] = 1\n",
    "                #print(k)\n",
    "            n = l[0]/vocabu[1]\n",
    "            p = l[1]/vocabu[2]\n",
    "            nega *= (n*700)**vect[word]\n",
    "            posi *= (p*700)**vect[word]\n",
    "            #print(p)\n",
    "        #else:\n",
    "            #print(k+' is not in vocabulary ')\n",
    "    return (nega,posi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 376 0.0 0 % accurate\n"
     ]
    }
   ],
   "source": [
    "#global vocabu\n",
    "def naive_bayes(f):\n",
    "    vect,wc = freq(f)\n",
    "    posi = 1\n",
    "    nega = 1 #probability\n",
    "    #print(vect.keys())\n",
    "    for word in vocabu[0].keys():#vect.keys():\n",
    "        #if word in vocabu[0]:\n",
    "        l = vocabu[0][word]\n",
    "        if l[0] == 0:\n",
    "                #print(k)\n",
    "            l[0] = 1\n",
    "        if l[1] == 0:\n",
    "            l[1] = 1\n",
    "                #print(k)\n",
    "        wrd_pr = (l[0]+l[1])/(vocabu[3]+vocabu[4])\n",
    "        if word in vect:#present:\n",
    "            n = (l[0]/vocabu[1])/wrd_pr #pr(word=present|neg)/pr(word) #l[0]/vocabu[1]\n",
    "            p = (l[1]/vocabu[2])/wrd_pr\n",
    "        else:\n",
    "            n = ((vocabu[3] - l[0])/vocabu[1])/wrd_pr\n",
    "            p = ((vocabu[4] - l[1])/vocabu[2])/wrd_pr #pr(word=not_present|pos)/pr(word)\n",
    "        nega *= n#(n*700)**vect[word]\n",
    "        posi *= n#(p*700)**vect[word]\n",
    "            #print(p)\n",
    "        #else:\n",
    "            #print(k+' is not in vocabulary ')\n",
    "    return (nega*(vocabu[3]/(vocabu[3]+vocabu[4])),posi*(vocabu[4]/(vocabu[3]+vocabu[4])))\n",
    "crt = 0\n",
    "eq = 0\n",
    "total = 0\n",
    "for f in neg_test:\n",
    "    x = naive_bayes('dataset/txt_sentoken/neg_test/'+f)\n",
    "    if x == 'negative':#x[0] > x[1]:\n",
    "        crt += 1\n",
    "    #elif x[0] == x[0]:\n",
    "    #    eq += 1\n",
    "    total += 1\n",
    "for f in pos_test:\n",
    "    x = naive_bayes('dataset/txt_sentoken/pos_test/'+f)\n",
    "    if x == 'positive':#x[0] < x[1]:\n",
    "        crt += 1\n",
    "    #elif x[0] == x[1]:\n",
    "    #    eq += 1\n",
    "    total += 1\n",
    "print(crt,total,crt/total*100,eq ,\"% accurate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls dataset/txt_sentoken/neg_test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(vocab,index=vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes('dataset/txt_sentoken/pos_test/cv005_29443.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
