{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "NaiveBayes.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kadapallaNithin/nitandhra/blob/master/DataScience/NaiveBayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "FPgYPJ7oXeNQ",
        "colab_type": "text"
      },
      "source": [
        "# Movie Review - Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKAWysAxXeNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amnw7FPmXeN7",
        "colab_type": "code",
        "colab": {},
        "outputId": "99c0773b-75f8-4085-d06d-dc8a70fa79aa"
      },
      "source": [
        "print(os.getcwd())\n",
        "fol=os.getcwd()+'/tf.ipynb'\n",
        "fol1=open(fol)\n",
        "print(fol1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/nithin/Desktop/learn/3 2/DataScience/Lab\n",
            "<_io.TextIOWrapper name='/home/nithin/Desktop/learn/3 2/DataScience/Lab/tf.ipynb' mode='r' encoding='UTF-8'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2tyYEhkXeOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neg = os.listdir('dataset/txt_sentoken/neg') #neg = !ls dataset/txt_sentoken/neg \n",
        "pos = os.listdir('dataset/txt_sentoken/pos') #!ls dataset/txt_sentoken/pos\n",
        "neg_test = !ls dataset/txt_sentoken/neg_test\n",
        "pos_test = !ls dataset/txt_sentoken/pos_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMzm_KkJXeOu",
        "colab_type": "code",
        "colab": {},
        "outputId": "8009ecab-e742-4408-b1b3-8ae9dadc0fb6"
      },
      "source": [
        "parent_path = \"dataset/txt_sentoken/\"\n",
        "print(len(neg))\n",
        "print(len(pos))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "798\n",
            "798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVdYy9QKXeO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabu= [{},0,0,0,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmMe5PhAXePQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#vocabu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ1z3VAHXePb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#global vocabu\n",
        "def build_voc():\n",
        "    for fol in [('neg/',neg,0),('pos/',pos,1)]:\n",
        "        vocabu[3+fol[2]] = len(fol[1])\n",
        "        for fil in fol[1]:\n",
        "            if os.path.exists(parent_path+fol[0]+fil):\n",
        "                for line in open(parent_path+fol[0]+fil,'r').read().split(sep='\\n'):\n",
        "                    for word in line.split(sep=' '):\n",
        "                        if word in vocabu[0]:\n",
        "                            vocabu[0][word][fol[2]] += 1\n",
        "                        else:\n",
        "                            vocabu[0][word] = [0,0]\n",
        "                            vocabu[0][word][fol[2]] = 1\n",
        "                        vocabu[fol[2]+1] += 1\n",
        "            else:\n",
        "                print(\"Something fishy\")\n",
        "build_voc()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWY02QQFXePo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  #pd.read_csv(dire+'neg/'+neg[0],sep=' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR2krIc4XeP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#vocabu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc5jLN-OXeQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def freq(fil):\n",
        "    vect = {}\n",
        "    wc = 0\n",
        "    for line in open(fil,'r').read().split(sep='\\n'):\n",
        "        for word in line.split(sep=' '):\n",
        "            #if word in vocab:\n",
        "            if word in vect:\n",
        "                vect[word] += 1\n",
        "            else:\n",
        "                vect[word] = 1\n",
        "            wc += 1\n",
        "    return (vect,wc)\n",
        "#freq('dataset/txt_sentoken/pos/cv086_18371.txt')                "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArLjQq4NXeQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#global vocabu\n",
        "def naive_bayes(f):\n",
        "    vect,wc = freq(f)\n",
        "    posi = 0\n",
        "    nega = 0 #probability\n",
        "    #print(vect.keys())\n",
        "    for word in vect.keys():\n",
        "        if word in vocabu[0]:\n",
        "            l = vocabu[0][word]\n",
        "            if l[0] == 0:\n",
        "                #print(k)\n",
        "                l[0] = 1\n",
        "            if l[1] == 0:\n",
        "                l[1] = 1\n",
        "                #print(k)\n",
        "            n = l[0]/vocabu[1]\n",
        "            p = l[1]/vocabu[2]\n",
        "            nega += math.log10(n)*vect[word]\n",
        "            posi += math.log10(p)*vect[word]\n",
        "            #print(p)\n",
        "        #else:\n",
        "            #print(k+' is not in vocabulary ')\n",
        "    #print(nega,posi)\n",
        "    if nega > posi:\n",
        "        return (0,(vect,wc))\n",
        "    return (1,(vect,wc))\n",
        "#    return (10**nega,10**posi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95I-RQ8JXeQf",
        "colab_type": "code",
        "colab": {},
        "outputId": "fd8f1cac-46a4-4042-8de6-ef88e33d150a"
      },
      "source": [
        "naive_bayes('dataset/txt_sentoken/pos_test/cv041_21113.txt')[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'dataset/txt_sentoken/pos_test/cv041_21113.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-97edf49f1a58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnaive_bayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset/txt_sentoken/pos_test/cv041_21113.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-4c83105c7c9f>\u001b[0m in \u001b[0;36mnaive_bayes\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#global vocabu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnaive_bayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mvect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mposi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnega\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m#probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-57c6fa157794>\u001b[0m in \u001b[0;36mfreq\u001b[0;34m(fil)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mvect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mwc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfil\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;31m#if word in vocab:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/txt_sentoken/pos_test/cv041_21113.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I93s97eOXeQt",
        "colab_type": "code",
        "colab": {},
        "outputId": "a95450f6-326b-4203-949a-e15df63f3233"
      },
      "source": [
        "crt = 0\n",
        "incrt = list()\n",
        "eq = 0\n",
        "total = 0\n",
        "for f in neg_test:\n",
        "    x = naive_bayes('dataset/txt_sentoken/neg_test/'+f)\n",
        "    if x[0] == 0:#x == 'negative':#x[0] > x[1]:\n",
        "        crt += 1\n",
        "    #elif x[0] == x[0]:\n",
        "    #    eq += 1\n",
        "    else:\n",
        "        incrt.append(x[1])\n",
        "    total += 1\n",
        "for f in pos_test:\n",
        "    x = naive_bayes('dataset/txt_sentoken/pos_test/'+f)\n",
        "    if x[0] == 1:#x == 'positive':#x[0] < x[1]:\n",
        "        crt += 1\n",
        "    #elif x[0] == x[1]:\n",
        "    #    eq += 1\n",
        "    else:\n",
        "        incrt.append((x[1]))\n",
        "    total += 1\n",
        "print(crt,total,crt/total*100, \"% accurate\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "323 404 79.95049504950495 % accurate\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nySzUN-uXeQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruETo_MhXeRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#global vocabu\n",
        "def naive_bayes(f):\n",
        "    vect,wc = freq(f)\n",
        "    posi = 1\n",
        "    nega = 1 #probability\n",
        "    #print(vect.keys())\n",
        "    for word in vect.keys():\n",
        "        if word in vocabu[0]:\n",
        "            l = vocabu[0][word]\n",
        "            if l[0] == 0:\n",
        "                #print(k)\n",
        "                l[0] = 1\n",
        "            if l[1] == 0:\n",
        "                l[1] = 1\n",
        "                #print(k)\n",
        "            n = l[0]/vocabu[1]\n",
        "            p = l[1]/vocabu[2]\n",
        "            nega *= (n*700)**vect[word]\n",
        "            posi *= (p*700)**vect[word]\n",
        "            #print(p)\n",
        "        #else:\n",
        "            #print(k+' is not in vocabulary ')\n",
        "    return (nega,posi)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6CTCv7UXeRZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "44e2467a-923c-49a9-e9b1-916c357d1c85"
      },
      "source": [
        "#global vocabu\n",
        "def naive_bayes(f):\n",
        "    vect,wc = freq(f)\n",
        "    posi = 1\n",
        "    nega = 1 #probability\n",
        "    #print(vect.keys())\n",
        "    for word in vocabu[0].keys():#vect.keys():\n",
        "        #if word in vocabu[0]:\n",
        "        l = vocabu[0][word]\n",
        "        if l[0] == 0:\n",
        "                #print(k)\n",
        "            l[0] = 1\n",
        "        if l[1] == 0:\n",
        "            l[1] = 1\n",
        "                #print(k)\n",
        "        wrd_pr = (l[0]+l[1])/(vocabu[3]+vocabu[4])\n",
        "        if word in vect:#present:\n",
        "            n = (l[0]/vocabu[1])/wrd_pr #pr(word=present|neg)/pr(word) #l[0]/vocabu[1]\n",
        "            p = (l[1]/vocabu[2])/wrd_pr\n",
        "        else:\n",
        "            n = ((vocabu[3] - l[0])/vocabu[1])/wrd_pr\n",
        "            p = ((vocabu[4] - l[1])/vocabu[2])/wrd_pr #pr(word=not_present|pos)/pr(word)\n",
        "        nega *= n#(n*700)**vect[word]\n",
        "        posi *= n#(p*700)**vect[word]\n",
        "            #print(p)\n",
        "        #else:\n",
        "            #print(k+' is not in vocabulary ')\n",
        "    return (nega*(vocabu[3]/(vocabu[3]+vocabu[4])),posi*(vocabu[4]/(vocabu[3]+vocabu[4])))\n",
        "crt = 0\n",
        "eq = 0\n",
        "total = 0\n",
        "for f in neg_test:\n",
        "    x = naive_bayes('dataset/txt_sentoken/neg_test/'+f)\n",
        "    if x == 'negative':#x[0] > x[1]:\n",
        "        crt += 1\n",
        "    #elif x[0] == x[0]:\n",
        "    #    eq += 1\n",
        "    total += 1\n",
        "for f in pos_test:\n",
        "    x = naive_bayes('dataset/txt_sentoken/pos_test/'+f)\n",
        "    if x == 'positive':#x[0] < x[1]:\n",
        "        crt += 1\n",
        "    #elif x[0] == x[1]:\n",
        "    #    eq += 1\n",
        "    total += 1\n",
        "print(crt,total,crt/total*100,eq ,\"% accurate\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 376 0.0 0 % accurate\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6y_NeMYXeRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls dataset/txt_sentoken/neg_test/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCVMB_VIXeRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df = pd.DataFrame(vocab,index=vocab.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D4fM5wLXeR8",
        "colab_type": "code",
        "colab": {},
        "outputId": "448b8d3b-5263-4963-ae23-80071ebe3c4b"
      },
      "source": [
        "naive_bayes('dataset/txt_sentoken/pos_test/cv005_29443.txt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'positive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz9DjFdIXeSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}